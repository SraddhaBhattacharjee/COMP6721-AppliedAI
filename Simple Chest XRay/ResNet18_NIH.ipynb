{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naOl1p_8N5kl",
        "outputId": "2d780c03-76aa-4c5c-bcb1-d0306d7d8fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "id": "naOl1p_8N5kl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9b3415d"
      },
      "outputs": [],
      "source": [
        "import os, time, random, torch, warnings\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "id": "b9b3415d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OHDnzINmaWL"
      },
      "outputs": [],
      "source": [
        "#data_path = \"drive/My Drive/Simple_Chest_XRay/\"\n",
        "data_path = \"drive/My Drive/NIH_Chest_XRay/\"\n",
        "#data_path = \"drive/My Drive/Harvard_Chest_XRay/\"\n",
        "\n",
        "sample_ratio = 1\n",
        "batch_size = 64\n",
        "num_epochs = 20"
      ],
      "id": "4OHDnzINmaWL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j30qTJnkpvd3"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "id": "j30qTJnkpvd3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekRi1x_nsNpx"
      },
      "source": [
        "**DATA PREPROCESSING**\n"
      ],
      "id": "ekRi1x_nsNpx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ijtwkIpZhs"
      },
      "outputs": [],
      "source": [
        "%run \"/content/drive/My Drive/Colab Notebooks/utils.ipynb\"\n",
        "dataset, train_loader, train_indices, test_loader, test_indices, val_loader, val_indices = data_preprocess(data_path, sample_ratio)"
      ],
      "id": "m8ijtwkIpZhs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8krRXxA2iy6"
      },
      "source": [
        " **DOWNLOAD RESNET18 MODEL AND TRAIN**\n"
      ],
      "id": "_8krRXxA2iy6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cJoqDX56E7l"
      },
      "outputs": [],
      "source": [
        "def save_metrics(loss, accuracy, model):\n",
        "  np.save(\"{}{}_train_loss.npy\".format(data_path, model), loss)\n",
        "  np.save(\"{}{}_train_accuracy.npy\".format(data_path, model), accuracy)"
      ],
      "id": "-cJoqDX56E7l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbe3fa8",
        "outputId": "00995da7-6894-4e67-acf1-60108980abd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.9.0\" to /root/.cache/torch/hub/v0.9.0.zip\n"
          ]
        }
      ],
      "source": [
        "# Define the ResNet18 model and set Pretraining to False to train model from scratch\n",
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained = False)\n",
        "model.fc = nn.Linear(512, len(dataset.classes))\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function as CrossEntropy and optimizer as Adam Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "losses, accuracies, true, pred, v_accuracies, v_losses = [], [], [], [], [], []\n",
        "\n",
        "# Train model on training set\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy, start_time = 0.0, 0.0, time.time()\n",
        "\n",
        "   with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
        "      for inputs, labels in train_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item() * inputs.size(0)\n",
        "          train_accuracy += torch.sum(preds == labels.data)\n",
        "          pred.extend(preds.cpu().numpy())\n",
        "          true.extend(labels.cpu().numpy())\n",
        "          \n",
        "          pbar.set_postfix({'loss': loss.item()})\n",
        "          pbar.update()\n",
        "\n",
        "    train_loss /= len(train_indices)\n",
        "    train_accuracy /= len(train_indices)\n",
        "    _recall = recall_score(true, pred, average='macro')\n",
        "    _precision = precision_score(true, pred, average='macro')\n",
        "    _fscore = f1_score(true, pred, average='macro')\n",
        "\n",
        "    print('Epoch: {} | Accuracy: {:.4f} | Loss: {:.4f} | Recall: {:.4f} | Precision: {:.4f} | F-Score: {:.4f} | Time: {:.4f}s'.format(epoch+1, train_accuracy, train_loss, _recall, _precision, _fscore, time.time() - start_time))\n",
        "    val_accuracy, val_loss = evaluate_model(model, val_loader, val_indices, 'VALIDATION', criterion, data_path, \"ResNet18\")\n",
        "    v_accuracies.append(val_accuracy)\n",
        "    v_losses.append(val_loss)\n",
        "    losses.append(train_loss)\n",
        "    accuracies.append(train_accuracy.item())\n",
        "\n",
        "save_metrics(losses, accuracies, \"ResNet18\")"
      ],
      "id": "adbe3fa8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNvKSdNUTL5o"
      },
      "source": [
        "**SAVE MODEL PARAMETERS**"
      ],
      "id": "tNvKSdNUTL5o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AEMNS3KCIwi"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"{}resnet18.pth\".format(data_path))"
      ],
      "id": "_AEMNS3KCIwi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujIIcw9XEiNS"
      },
      "outputs": [],
      "source": [
        "#Plotting the Loss and Accuracy Curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "ax1.plot(losses, label = \"Training Loss\")\n",
        "ax1.plot(v_losses, label = \"Validation Loss\")\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss Curve')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(accuracies, label = \"Training Accuracy\")\n",
        "ax2.plot(v_accuracies, label = \"Validation Accuracy\")\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Training and Validation Accuracy Curve')\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "id": "ujIIcw9XEiNS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O3rqTRw3CmU"
      },
      "source": [
        "**EVALUATE MODEL ON TEST SET**"
      ],
      "id": "9O3rqTRw3CmU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbgkKSF1Klza"
      },
      "outputs": [],
      "source": [
        "#Evaluate Model on Test Set\n",
        "evaluate_model(model, test_loader, test_indices, 'TEST', criterion, data_path, \"ResNet18\")"
      ],
      "id": "UbgkKSF1Klza"
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain the TSNE Plot for the data\n",
        "features = []\n",
        "labels = []\n",
        "for images, targets in train_loader:\n",
        "    with torch.no_grad():\n",
        "        output = model(images)\n",
        "        features.append(output.cpu().numpy())\n",
        "        labels.append(targets.numpy())\n",
        "\n",
        "features = np.vstack(features)\n",
        "labels = np.concatenate(labels)\n",
        "\n",
        "# Perform t-SNE on the feature vectors\n",
        "tsne = TSNE(n_components=2, perplexity = 20, learning_rate = 600, n_iter = 900)\n",
        "tsne_features = tsne.fit_transform(features)\n",
        "\n",
        "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=labels, cmap=plt.cm.get_cmap('jet', len(dataset.classes)))\n",
        "plt.legend()\n",
        "plt.title('t-SNE Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h82ix8mf9LDH"
      },
      "id": "h82ix8mf9LDH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class labels and the number of classes\n",
        "class_labels = dataset.classes\n",
        "num_classes = len(class_labels)\n",
        "\n",
        "# Get the number of images per class\n",
        "num_images_per_class = []\n",
        "for i in range(num_classes):\n",
        "    class_indices = np.where(np.array(dataset.targets) == i)[0]\n",
        "    num_images_per_class.append(len(class_indices))\n",
        "\n",
        "# Compute the mean and variance of the images per class\n",
        "mean_num_images = np.mean(num_images_per_class)\n",
        "var_num_images = np.var(num_images_per_class)\n",
        "\n",
        "# Plot the within-class variance\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(class_labels, num_images_per_class)\n",
        "ax.axhline(y=mean_num_images, linestyle='--', color='r', label='Mean')\n",
        "ax.axhspan(mean_num_images - np.sqrt(var_num_images), mean_num_images + np.sqrt(var_num_images),\n",
        "           alpha=0.2, color='y', label='Variance')\n",
        "ax.legend()\n",
        "plt.xticks(rotation = 0)\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xlabel('Class Labels')\n",
        "plt.title('Within-Class Variance Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ysU_s9T9P4d"
      },
      "id": "_ysU_s9T9P4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def within_class_variance(dataset, model):\n",
        "    # Set the model to evaluation mode\n",
        "    model.load_state_dict(model['model_state_dict'])\n",
        "    model.eval()\n",
        "    # Get the feature vectors and labels for the dataset\n",
        "    features = []\n",
        "    labels = []\n",
        "    for images, targets in train_loader:\n",
        "        with torch.no_grad():\n",
        "          images = images.to(device)\n",
        "          targets = targets.to(device)\n",
        "          output = model(images)\n",
        "          features.append(output.cpu().numpy()[0])\n",
        "          labels.append(targets.cpu().numpy()[0])\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "    \n",
        "    # Calculate the within-class variance for each class\n",
        "    class_variances = []\n",
        "    for c in np.unique(labels):\n",
        "        class_features = features[labels == c]\n",
        "        class_mean = np.mean(class_features, axis=0)\n",
        "        class_variance = np.mean(np.sum((class_features - class_mean)**2, axis=1))\n",
        "        class_variances.append(class_variance)\n",
        "    \n",
        "    return class_variances\n",
        "\n",
        "# Define the dataset and model\n",
        "# Calculate the within-class variance\n",
        "class_variances = within_class_variance(dataset, model)\n",
        "\n",
        "# Plot the within-class variances for each class\n",
        "plt.bar(np.arange(len(class_variances)), class_variances)\n",
        "plt.xticks(np.arange(len(class_variances)), dataset.classes, rotation='vertical')\n",
        "plt.ylabel('Within-class variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QpgARsLs9Stl"
      },
      "id": "QpgARsLs9Stl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}