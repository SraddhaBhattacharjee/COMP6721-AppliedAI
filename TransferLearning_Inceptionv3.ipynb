{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshansadath/COMP6721-AppliedAI/blob/main/TransferLearning_Inceptionv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naOl1p_8N5kl",
        "outputId": "1f4b4a2b-e274-478b-807b-5c5693abd817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "id": "naOl1p_8N5kl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9b3415d"
      },
      "outputs": [],
      "source": [
        "import os, time, random\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.models.inception import InceptionOutputs\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "%run \"/content/drive/My Drive/Colab Notebooks/utils.ipynb\""
      ],
      "id": "b9b3415d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OHDnzINmaWL"
      },
      "outputs": [],
      "source": [
        "#data_path = \"drive/My Drive/Simple_Chest_XRay/\"\n",
        "#data_path = \"drive/My Drive/NIH_Chest_XRay/\"\n",
        "data_path = \"drive/My Drive/Harvard_Chest_XRay/\"\n",
        "\n",
        "sample_ratio = 0.4\n",
        "batch_size = 64\n",
        "num_epochs = 12"
      ],
      "id": "4OHDnzINmaWL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j30qTJnkpvd3"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "id": "j30qTJnkpvd3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekRi1x_nsNpx"
      },
      "source": [
        "**DATA PREPROCESSING**\n"
      ],
      "id": "ekRi1x_nsNpx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RNVwBbTv8xP"
      },
      "outputs": [],
      "source": [
        "def data_sampling(indices):\n",
        "  return torch.utils.data.sampler.SubsetRandomSampler(indices)"
      ],
      "id": "7RNVwBbTv8xP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ijtwkIpZhs"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([\n",
        "  transforms.Resize((299, 299)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "# Get dataset from folder and apply data transforms\n",
        "dataset = datasets.ImageFolder(root = \"{}data\".format(data_path), transform = data_transforms)\n",
        "  \n",
        "# Get a sample of the data randomly\n",
        "num_samples = int(len(dataset) * sample_ratio)\n",
        "indices = np.random.choice(range(len(dataset)), num_samples, replace = False)\n",
        "\n",
        "# Split the data into training, test, and validation sets\n",
        "train_size = int(0.7 * num_samples)\n",
        "test_size = int(0.2 * num_samples)\n",
        "val_size = num_samples - train_size - test_size\n",
        "\n",
        "train_indices = indices[ : train_size]\n",
        "test_indices = indices[train_size : train_size + test_size]\n",
        "val_indices = indices[train_size + test_size : ]\n",
        "\n",
        "samples = [data_sampling(i) for i in [train_indices, test_indices, val_indices]]\n",
        "\n",
        "# Create data loaders for training, test, and validation sets\n",
        "train_loader = DataLoader(dataset, batch_size = batch_size, sampler = samples[0])\n",
        "test_loader = DataLoader(dataset, batch_size = batch_size, sampler = samples[1])\n",
        "val_loader = DataLoader(dataset, batch_size = batch_size, sampler = samples[2])"
      ],
      "id": "m8ijtwkIpZhs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8krRXxA2iy6"
      },
      "source": [
        " **DOWNLOAD RESNET18 MODEL AND TRAIN**\n"
      ],
      "id": "_8krRXxA2iy6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cJoqDX56E7l"
      },
      "outputs": [],
      "source": [
        "def save_metrics(loss, accuracy, model):\n",
        "  np.save(\"{}{}_train_loss.npy\".format(data_path, model), loss)\n",
        "  np.save(\"{}{}_train_accuracy.npy\".format(data_path, model), accuracy)"
      ],
      "id": "-cJoqDX56E7l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "adbe3fa8",
        "outputId": "ead76675-31c1-4b50-8142-da474520d2e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-576dc9d5024d>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInceptionOutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInceptionOutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define the Inceptionv3 model and load the pretrained model from Dataset3 and perform Deep-tuning\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = torch.load(\"{}inceptionv3.pth\".format(data_path))\n",
        "\n",
        "for params in model.parameters():\n",
        "  params.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function as CrossEntropy and optimizer as Adam Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0005)\n",
        "losses, accuracies, v_accuracies, v_losses = train_model(model, criterion, optimizer, \"TL_Inceptionv3\", num_epochs)"
      ],
      "id": "adbe3fa8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNvKSdNUTL5o"
      },
      "source": [
        "**SAVE MODEL PARAMETERS**"
      ],
      "id": "tNvKSdNUTL5o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AEMNS3KCIwi"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"{}TL_inceptionv3.pth\".format(data_path))"
      ],
      "id": "_AEMNS3KCIwi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujIIcw9XEiNS"
      },
      "outputs": [],
      "source": [
        "#Plot the Accuracy and Loss Curves of the model for Training and Validation\n",
        "plot_model_curves(losses, accuracies, v_accuracies, v_losses)"
      ],
      "id": "ujIIcw9XEiNS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O3rqTRw3CmU"
      },
      "source": [
        "**EVALUATE MODEL ON VALIDATION AND TEST SET**"
      ],
      "id": "9O3rqTRw3CmU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbgkKSF1Klza"
      },
      "outputs": [],
      "source": [
        "#Evaluate Model on Test Set\n",
        "evaluate_model(model, test_loader, test_indices, 'TEST', criterion, data_path, \"Inceptionv3\")"
      ],
      "id": "UbgkKSF1Klza"
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain the TSNE Plot\n",
        "plotTSNE(train_loader, device, model)"
      ],
      "metadata": {
        "id": "NUGg0Y5H2XKR"
      },
      "id": "NUGg0Y5H2XKR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the Within-Class Variance of the dataset\n",
        "plot_within_class_variance(dataset)"
      ],
      "metadata": {
        "id": "fltcNw112ZM9"
      },
      "id": "fltcNw112ZM9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}